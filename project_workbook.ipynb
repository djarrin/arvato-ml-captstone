{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "If you completed the first term of this program, you will be familiar with the first part of this project, from the unsupervised learning project. The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "bucket: sagemaker-us-east-1-709677954768\n"
     ]
    }
   ],
   "source": [
    "# Setup Sagemaker Session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "execution_role = sagemaker.session.get_execution_role()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "print(f'bucket: {bucket}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#download data to notebook\n",
    "#define data location constants\n",
    "local_data_dir = 'data'\n",
    "s3_data_path = f's3://{bucket}/data' \n",
    "s3_model_path = f's3://{bucket}/model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initial Model and Kaggle Submission\n",
    "\n",
    "Below I will be setting up the an initial AutoGluon run without any refienment of the data. Then I'll be submitting to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install -U pip\n",
    "!pip install -U setuptools wheel\n",
    "!pip install -U \"mxnet<2.0.0\" bokeh==2.0.1\n",
    "!pip install autogluon --no-cache-dir\n",
    "!pip install kaggle\n",
    "!pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Kaggle Creds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KAGGLE_CONFIG_DIR=kaggle\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p kaggle\n",
    "%env KAGGLE_CONFIG_DIR=kaggle\n",
    "!touch kaggle/kaggle.json\n",
    "!chmod 600 kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "CONFIG = dotenv_values('env.txt')\n",
    "kaggle_username = CONFIG['KAGGLE_USERNAME']\n",
    "kaggle_key = CONFIG['KAGGLE_KEY']\n",
    "\n",
    "# Save API token the kaggle.json file\n",
    "with open(\"kaggle/kaggle.json\", \"w\") as f:\n",
    "    f.write(json.dumps({\"username\": kaggle_username, \"key\": kaggle_key}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
